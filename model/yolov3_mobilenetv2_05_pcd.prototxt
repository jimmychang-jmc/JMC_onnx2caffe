layer {
  name: "img"
  type: "Input"
  top: "img"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 416
      dim: 416
    }
  }
}
layer {
  name: "433"
  type: "Convolution"
  bottom: "img"
  top: "433"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "434_bn"
  type: "BatchNorm"
  bottom: "433"
  top: "434"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "434"
  type: "Scale"
  bottom: "434"
  top: "434"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "435"
  type: "ReLU"
  bottom: "434"
  top: "435"
}
layer {
  name: "436"
  type: "Convolution"
  bottom: "435"
  top: "436"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 16
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "437_bn"
  type: "BatchNorm"
  bottom: "436"
  top: "437"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "437"
  type: "Scale"
  bottom: "437"
  top: "437"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "438"
  type: "ReLU"
  bottom: "437"
  top: "438"
}
layer {
  name: "439"
  type: "Convolution"
  bottom: "438"
  top: "439"
  convolution_param {
    num_output: 8
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "440_bn"
  type: "BatchNorm"
  bottom: "439"
  top: "440"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "440"
  type: "Scale"
  bottom: "440"
  top: "440"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "441"
  type: "Convolution"
  bottom: "440"
  top: "441"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "442_bn"
  type: "BatchNorm"
  bottom: "441"
  top: "442"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "442"
  type: "Scale"
  bottom: "442"
  top: "442"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "443"
  type: "ReLU"
  bottom: "442"
  top: "443"
}
layer {
  name: "444"
  type: "Convolution"
  bottom: "443"
  top: "444"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "445_bn"
  type: "BatchNorm"
  bottom: "444"
  top: "445"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "445"
  type: "Scale"
  bottom: "445"
  top: "445"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "446"
  type: "ReLU"
  bottom: "445"
  top: "446"
}
layer {
  name: "447"
  type: "Convolution"
  bottom: "446"
  top: "447"
  convolution_param {
    num_output: 12
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "448_bn"
  type: "BatchNorm"
  bottom: "447"
  top: "448"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "448"
  type: "Scale"
  bottom: "448"
  top: "448"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "449"
  type: "Convolution"
  bottom: "448"
  top: "449"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "450_bn"
  type: "BatchNorm"
  bottom: "449"
  top: "450"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "450"
  type: "Scale"
  bottom: "450"
  top: "450"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "451"
  type: "ReLU"
  bottom: "450"
  top: "451"
}
layer {
  name: "452"
  type: "Convolution"
  bottom: "451"
  top: "452"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 72
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "453_bn"
  type: "BatchNorm"
  bottom: "452"
  top: "453"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "453"
  type: "Scale"
  bottom: "453"
  top: "453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "454"
  type: "ReLU"
  bottom: "453"
  top: "454"
}
layer {
  name: "455"
  type: "Convolution"
  bottom: "454"
  top: "455"
  convolution_param {
    num_output: 12
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "456_bn"
  type: "BatchNorm"
  bottom: "455"
  top: "456"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "456"
  type: "Scale"
  bottom: "456"
  top: "456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "457"
  type: "Eltwise"
  bottom: "448"
  bottom: "456"
  top: "457"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "458"
  type: "Convolution"
  bottom: "457"
  top: "458"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "459_bn"
  type: "BatchNorm"
  bottom: "458"
  top: "459"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "459"
  type: "Scale"
  bottom: "459"
  top: "459"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "460"
  type: "ReLU"
  bottom: "459"
  top: "460"
}
layer {
  name: "461"
  type: "Convolution"
  bottom: "460"
  top: "461"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 72
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "462_bn"
  type: "BatchNorm"
  bottom: "461"
  top: "462"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "462"
  type: "Scale"
  bottom: "462"
  top: "462"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "463"
  type: "ReLU"
  bottom: "462"
  top: "463"
}
layer {
  name: "464"
  type: "Convolution"
  bottom: "463"
  top: "464"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "465_bn"
  type: "BatchNorm"
  bottom: "464"
  top: "465"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "465"
  type: "Scale"
  bottom: "465"
  top: "465"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "466"
  type: "Convolution"
  bottom: "465"
  top: "466"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "467_bn"
  type: "BatchNorm"
  bottom: "466"
  top: "467"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "467"
  type: "Scale"
  bottom: "467"
  top: "467"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "468"
  type: "ReLU"
  bottom: "467"
  top: "468"
}
layer {
  name: "469"
  type: "Convolution"
  bottom: "468"
  top: "469"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "470_bn"
  type: "BatchNorm"
  bottom: "469"
  top: "470"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "470"
  type: "Scale"
  bottom: "470"
  top: "470"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "471"
  type: "ReLU"
  bottom: "470"
  top: "471"
}
layer {
  name: "472"
  type: "Convolution"
  bottom: "471"
  top: "472"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "473_bn"
  type: "BatchNorm"
  bottom: "472"
  top: "473"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "473"
  type: "Scale"
  bottom: "473"
  top: "473"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "474"
  type: "Eltwise"
  bottom: "465"
  bottom: "473"
  top: "474"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "475"
  type: "Convolution"
  bottom: "474"
  top: "475"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "476_bn"
  type: "BatchNorm"
  bottom: "475"
  top: "476"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "476"
  type: "Scale"
  bottom: "476"
  top: "476"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "477"
  type: "ReLU"
  bottom: "476"
  top: "477"
}
layer {
  name: "478"
  type: "Convolution"
  bottom: "477"
  top: "478"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "479_bn"
  type: "BatchNorm"
  bottom: "478"
  top: "479"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "479"
  type: "Scale"
  bottom: "479"
  top: "479"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "480"
  type: "ReLU"
  bottom: "479"
  top: "480"
}
layer {
  name: "481"
  type: "Convolution"
  bottom: "480"
  top: "481"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "482_bn"
  type: "BatchNorm"
  bottom: "481"
  top: "482"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "482"
  type: "Scale"
  bottom: "482"
  top: "482"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "483"
  type: "Eltwise"
  bottom: "474"
  bottom: "482"
  top: "483"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "484"
  type: "Convolution"
  bottom: "483"
  top: "484"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "485_bn"
  type: "BatchNorm"
  bottom: "484"
  top: "485"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "485"
  type: "Scale"
  bottom: "485"
  top: "485"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "486"
  type: "ReLU"
  bottom: "485"
  top: "486"
}
layer {
  name: "487"
  type: "Convolution"
  bottom: "486"
  top: "487"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "488_bn"
  type: "BatchNorm"
  bottom: "487"
  top: "488"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "488"
  type: "Scale"
  bottom: "488"
  top: "488"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "489"
  type: "ReLU"
  bottom: "488"
  top: "489"
}
layer {
  name: "490"
  type: "Convolution"
  bottom: "489"
  top: "490"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "491_bn"
  type: "BatchNorm"
  bottom: "490"
  top: "491"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "491"
  type: "Scale"
  bottom: "491"
  top: "491"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "492"
  type: "Convolution"
  bottom: "491"
  top: "492"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "493_bn"
  type: "BatchNorm"
  bottom: "492"
  top: "493"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "493"
  type: "Scale"
  bottom: "493"
  top: "493"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "494"
  type: "ReLU"
  bottom: "493"
  top: "494"
}
layer {
  name: "495"
  type: "Convolution"
  bottom: "494"
  top: "495"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "496_bn"
  type: "BatchNorm"
  bottom: "495"
  top: "496"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "496"
  type: "Scale"
  bottom: "496"
  top: "496"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "497"
  type: "ReLU"
  bottom: "496"
  top: "497"
}
layer {
  name: "498"
  type: "Convolution"
  bottom: "497"
  top: "498"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "499_bn"
  type: "BatchNorm"
  bottom: "498"
  top: "499"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "499"
  type: "Scale"
  bottom: "499"
  top: "499"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "500"
  type: "Eltwise"
  bottom: "491"
  bottom: "499"
  top: "500"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "501"
  type: "Convolution"
  bottom: "500"
  top: "501"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "502_bn"
  type: "BatchNorm"
  bottom: "501"
  top: "502"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "502"
  type: "Scale"
  bottom: "502"
  top: "502"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "503"
  type: "ReLU"
  bottom: "502"
  top: "503"
}
layer {
  name: "504"
  type: "Convolution"
  bottom: "503"
  top: "504"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "505_bn"
  type: "BatchNorm"
  bottom: "504"
  top: "505"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "505"
  type: "Scale"
  bottom: "505"
  top: "505"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "506"
  type: "ReLU"
  bottom: "505"
  top: "506"
}
layer {
  name: "507"
  type: "Convolution"
  bottom: "506"
  top: "507"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "508_bn"
  type: "BatchNorm"
  bottom: "507"
  top: "508"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "508"
  type: "Scale"
  bottom: "508"
  top: "508"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "509"
  type: "Eltwise"
  bottom: "500"
  bottom: "508"
  top: "509"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "510"
  type: "Convolution"
  bottom: "509"
  top: "510"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "511_bn"
  type: "BatchNorm"
  bottom: "510"
  top: "511"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "511"
  type: "Scale"
  bottom: "511"
  top: "511"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "512"
  type: "ReLU"
  bottom: "511"
  top: "512"
}
layer {
  name: "513"
  type: "Convolution"
  bottom: "512"
  top: "513"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "514_bn"
  type: "BatchNorm"
  bottom: "513"
  top: "514"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "514"
  type: "Scale"
  bottom: "514"
  top: "514"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "515"
  type: "ReLU"
  bottom: "514"
  top: "515"
}
layer {
  name: "516"
  type: "Convolution"
  bottom: "515"
  top: "516"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "517_bn"
  type: "BatchNorm"
  bottom: "516"
  top: "517"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "517"
  type: "Scale"
  bottom: "517"
  top: "517"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "518"
  type: "Eltwise"
  bottom: "509"
  bottom: "517"
  top: "518"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "519"
  type: "Convolution"
  bottom: "518"
  top: "519"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "520_bn"
  type: "BatchNorm"
  bottom: "519"
  top: "520"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "520"
  type: "Scale"
  bottom: "520"
  top: "520"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "521"
  type: "ReLU"
  bottom: "520"
  top: "521"
}
layer {
  name: "522"
  type: "Convolution"
  bottom: "521"
  top: "522"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "523_bn"
  type: "BatchNorm"
  bottom: "522"
  top: "523"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "523"
  type: "Scale"
  bottom: "523"
  top: "523"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "524"
  type: "ReLU"
  bottom: "523"
  top: "524"
}
layer {
  name: "525"
  type: "Convolution"
  bottom: "524"
  top: "525"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "526_bn"
  type: "BatchNorm"
  bottom: "525"
  top: "526"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "526"
  type: "Scale"
  bottom: "526"
  top: "526"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "527"
  type: "Convolution"
  bottom: "526"
  top: "527"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "528_bn"
  type: "BatchNorm"
  bottom: "527"
  top: "528"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "528"
  type: "Scale"
  bottom: "528"
  top: "528"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "529"
  type: "ReLU"
  bottom: "528"
  top: "529"
}
layer {
  name: "530"
  type: "Convolution"
  bottom: "529"
  top: "530"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 288
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "531_bn"
  type: "BatchNorm"
  bottom: "530"
  top: "531"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "531"
  type: "Scale"
  bottom: "531"
  top: "531"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "532"
  type: "ReLU"
  bottom: "531"
  top: "532"
}
layer {
  name: "533"
  type: "Convolution"
  bottom: "532"
  top: "533"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "534_bn"
  type: "BatchNorm"
  bottom: "533"
  top: "534"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "534"
  type: "Scale"
  bottom: "534"
  top: "534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "535"
  type: "Eltwise"
  bottom: "526"
  bottom: "534"
  top: "535"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "536"
  type: "Convolution"
  bottom: "535"
  top: "536"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "537_bn"
  type: "BatchNorm"
  bottom: "536"
  top: "537"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "537"
  type: "Scale"
  bottom: "537"
  top: "537"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "538"
  type: "ReLU"
  bottom: "537"
  top: "538"
}
layer {
  name: "539"
  type: "Convolution"
  bottom: "538"
  top: "539"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 288
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "540_bn"
  type: "BatchNorm"
  bottom: "539"
  top: "540"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "540"
  type: "Scale"
  bottom: "540"
  top: "540"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "541"
  type: "ReLU"
  bottom: "540"
  top: "541"
}
layer {
  name: "542"
  type: "Convolution"
  bottom: "541"
  top: "542"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "543_bn"
  type: "BatchNorm"
  bottom: "542"
  top: "543"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "543"
  type: "Scale"
  bottom: "543"
  top: "543"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "544"
  type: "Eltwise"
  bottom: "535"
  bottom: "543"
  top: "544"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "545"
  type: "Convolution"
  bottom: "544"
  top: "545"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "546_bn"
  type: "BatchNorm"
  bottom: "545"
  top: "546"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "546"
  type: "Scale"
  bottom: "546"
  top: "546"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "547"
  type: "ReLU"
  bottom: "546"
  top: "547"
}
layer {
  name: "548"
  type: "Convolution"
  bottom: "547"
  top: "548"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 288
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "549_bn"
  type: "BatchNorm"
  bottom: "548"
  top: "549"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "549"
  type: "Scale"
  bottom: "549"
  top: "549"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "550"
  type: "ReLU"
  bottom: "549"
  top: "550"
}
layer {
  name: "551"
  type: "Convolution"
  bottom: "550"
  top: "551"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "552_bn"
  type: "BatchNorm"
  bottom: "551"
  top: "552"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "552"
  type: "Scale"
  bottom: "552"
  top: "552"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "553"
  type: "Convolution"
  bottom: "552"
  top: "553"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "554_bn"
  type: "BatchNorm"
  bottom: "553"
  top: "554"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "554"
  type: "Scale"
  bottom: "554"
  top: "554"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "555"
  type: "ReLU"
  bottom: "554"
  top: "555"
}
layer {
  name: "556"
  type: "Convolution"
  bottom: "555"
  top: "556"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 480
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "557_bn"
  type: "BatchNorm"
  bottom: "556"
  top: "557"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "557"
  type: "Scale"
  bottom: "557"
  top: "557"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "558"
  type: "ReLU"
  bottom: "557"
  top: "558"
}
layer {
  name: "559"
  type: "Convolution"
  bottom: "558"
  top: "559"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "560_bn"
  type: "BatchNorm"
  bottom: "559"
  top: "560"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "560"
  type: "Scale"
  bottom: "560"
  top: "560"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "561"
  type: "Eltwise"
  bottom: "552"
  bottom: "560"
  top: "561"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "562"
  type: "Convolution"
  bottom: "561"
  top: "562"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "563_bn"
  type: "BatchNorm"
  bottom: "562"
  top: "563"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "563"
  type: "Scale"
  bottom: "563"
  top: "563"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "564"
  type: "ReLU"
  bottom: "563"
  top: "564"
}
layer {
  name: "565"
  type: "Convolution"
  bottom: "564"
  top: "565"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 480
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "566_bn"
  type: "BatchNorm"
  bottom: "565"
  top: "566"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "566"
  type: "Scale"
  bottom: "566"
  top: "566"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "567"
  type: "ReLU"
  bottom: "566"
  top: "567"
}
layer {
  name: "568"
  type: "Convolution"
  bottom: "567"
  top: "568"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "569_bn"
  type: "BatchNorm"
  bottom: "568"
  top: "569"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "569"
  type: "Scale"
  bottom: "569"
  top: "569"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "570"
  type: "Eltwise"
  bottom: "561"
  bottom: "569"
  top: "570"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "571"
  type: "Convolution"
  bottom: "570"
  top: "571"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "572_bn"
  type: "BatchNorm"
  bottom: "571"
  top: "572"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "572"
  type: "Scale"
  bottom: "572"
  top: "572"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "573"
  type: "ReLU"
  bottom: "572"
  top: "573"
}
layer {
  name: "574"
  type: "Convolution"
  bottom: "573"
  top: "574"
  convolution_param {
    num_output: 480
    bias_term: false
    group: 480
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "575_bn"
  type: "BatchNorm"
  bottom: "574"
  top: "575"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "575"
  type: "Scale"
  bottom: "575"
  top: "575"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "576"
  type: "ReLU"
  bottom: "575"
  top: "576"
}
layer {
  name: "577"
  type: "Convolution"
  bottom: "576"
  top: "577"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "578_bn"
  type: "BatchNorm"
  bottom: "577"
  top: "578"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "578"
  type: "Scale"
  bottom: "578"
  top: "578"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "579"
  type: "Convolution"
  bottom: "578"
  top: "579"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "580_bn"
  type: "BatchNorm"
  bottom: "579"
  top: "580"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "580"
  type: "Scale"
  bottom: "580"
  top: "580"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "581"
  type: "ReLU"
  bottom: "580"
  top: "581"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "582"
  type: "Convolution"
  bottom: "581"
  top: "582"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "583_bn"
  type: "BatchNorm"
  bottom: "582"
  top: "583"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "583"
  type: "Scale"
  bottom: "583"
  top: "583"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "584"
  type: "ReLU"
  bottom: "583"
  top: "584"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "585"
  type: "Convolution"
  bottom: "584"
  top: "585"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "586_bn"
  type: "BatchNorm"
  bottom: "585"
  top: "586"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "586"
  type: "Scale"
  bottom: "586"
  top: "586"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "587"
  type: "ReLU"
  bottom: "586"
  top: "587"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "588"
  type: "Convolution"
  bottom: "587"
  top: "588"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "589_bn"
  type: "BatchNorm"
  bottom: "588"
  top: "589"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "589"
  type: "Scale"
  bottom: "589"
  top: "589"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "590"
  type: "ReLU"
  bottom: "589"
  top: "590"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "591"
  type: "Convolution"
  bottom: "590"
  top: "591"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "592_bn"
  type: "BatchNorm"
  bottom: "591"
  top: "592"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "592"
  type: "Scale"
  bottom: "592"
  top: "592"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "593"
  type: "ReLU"
  bottom: "592"
  top: "593"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "594"
  type: "Convolution"
  bottom: "593"
  top: "594"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "595_bn"
  type: "BatchNorm"
  bottom: "594"
  top: "595"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "595"
  type: "Scale"
  bottom: "595"
  top: "595"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "596"
  type: "ReLU"
  bottom: "595"
  top: "596"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature0"
  type: "Convolution"
  bottom: "596"
  top: "feature0"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "598"
  type: "Convolution"
  bottom: "593"
  top: "598"
  convolution_param {
    num_output: 40
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "599_bn"
  type: "BatchNorm"
  bottom: "598"
  top: "599"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "599"
  type: "Scale"
  bottom: "599"
  top: "599"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "600"
  type: "ReLU"
  bottom: "599"
  top: "600"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "602"
  type: "Deconvolution"
  bottom: "600"
  top: "602"
  convolution_param {
    num_output: 40
    bias_term: false
    kernel_size: 2
    group: 40
    stride: 2
  }
}
layer {
  name: "603"
  type: "Concat"
  bottom: "602"
  bottom: "544"
  top: "603"
  concat_param {
    axis: 1
  }
}
layer {
  name: "604"
  type: "Convolution"
  bottom: "603"
  top: "604"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "605_bn"
  type: "BatchNorm"
  bottom: "604"
  top: "605"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "605"
  type: "Scale"
  bottom: "605"
  top: "605"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "606"
  type: "ReLU"
  bottom: "605"
  top: "606"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "607"
  type: "Convolution"
  bottom: "606"
  top: "607"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "608_bn"
  type: "BatchNorm"
  bottom: "607"
  top: "608"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "608"
  type: "Scale"
  bottom: "608"
  top: "608"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "609"
  type: "ReLU"
  bottom: "608"
  top: "609"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "610"
  type: "Convolution"
  bottom: "609"
  top: "610"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "611_bn"
  type: "BatchNorm"
  bottom: "610"
  top: "611"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "611"
  type: "Scale"
  bottom: "611"
  top: "611"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "612"
  type: "ReLU"
  bottom: "611"
  top: "612"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "613"
  type: "Convolution"
  bottom: "612"
  top: "613"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "614_bn"
  type: "BatchNorm"
  bottom: "613"
  top: "614"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "614"
  type: "Scale"
  bottom: "614"
  top: "614"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "615"
  type: "ReLU"
  bottom: "614"
  top: "615"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "616"
  type: "Convolution"
  bottom: "615"
  top: "616"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "617_bn"
  type: "BatchNorm"
  bottom: "616"
  top: "617"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "617"
  type: "Scale"
  bottom: "617"
  top: "617"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "618"
  type: "ReLU"
  bottom: "617"
  top: "618"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "619"
  type: "Convolution"
  bottom: "618"
  top: "619"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "620_bn"
  type: "BatchNorm"
  bottom: "619"
  top: "620"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "620"
  type: "Scale"
  bottom: "620"
  top: "620"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "621"
  type: "ReLU"
  bottom: "620"
  top: "621"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature1"
  type: "Convolution"
  bottom: "621"
  top: "feature1"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "623"
  type: "Convolution"
  bottom: "618"
  top: "623"
  convolution_param {
    num_output: 14
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "624_bn"
  type: "BatchNorm"
  bottom: "623"
  top: "624"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "624"
  type: "Scale"
  bottom: "624"
  top: "624"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "625"
  type: "ReLU"
  bottom: "624"
  top: "625"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "627"
  type: "Deconvolution"
  bottom: "625"
  top: "627"
  convolution_param {
    num_output: 14
    bias_term: false
    kernel_size: 2
    group: 14
    stride: 2
  }
}
layer {
  name: "628"
  type: "Concat"
  bottom: "627"
  bottom: "483"
  top: "628"
  concat_param {
    axis: 1
  }
}
layer {
  name: "629"
  type: "Convolution"
  bottom: "628"
  top: "629"
  convolution_param {
    num_output: 10
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "630_bn"
  type: "BatchNorm"
  bottom: "629"
  top: "630"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "630"
  type: "Scale"
  bottom: "630"
  top: "630"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "631"
  type: "ReLU"
  bottom: "630"
  top: "631"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "632"
  type: "Convolution"
  bottom: "631"
  top: "632"
  convolution_param {
    num_output: 20
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "633_bn"
  type: "BatchNorm"
  bottom: "632"
  top: "633"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "633"
  type: "Scale"
  bottom: "633"
  top: "633"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "634"
  type: "ReLU"
  bottom: "633"
  top: "634"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "635"
  type: "Convolution"
  bottom: "634"
  top: "635"
  convolution_param {
    num_output: 10
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "636_bn"
  type: "BatchNorm"
  bottom: "635"
  top: "636"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "636"
  type: "Scale"
  bottom: "636"
  top: "636"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "637"
  type: "ReLU"
  bottom: "636"
  top: "637"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "638"
  type: "Convolution"
  bottom: "637"
  top: "638"
  convolution_param {
    num_output: 20
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "639_bn"
  type: "BatchNorm"
  bottom: "638"
  top: "639"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "639"
  type: "Scale"
  bottom: "639"
  top: "639"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "640"
  type: "ReLU"
  bottom: "639"
  top: "640"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "641"
  type: "Convolution"
  bottom: "640"
  top: "641"
  convolution_param {
    num_output: 10
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "642_bn"
  type: "BatchNorm"
  bottom: "641"
  top: "642"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "642"
  type: "Scale"
  bottom: "642"
  top: "642"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "643"
  type: "ReLU"
  bottom: "642"
  top: "643"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "644"
  type: "Convolution"
  bottom: "643"
  top: "644"
  convolution_param {
    num_output: 20
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "645_bn"
  type: "BatchNorm"
  bottom: "644"
  top: "645"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "645"
  type: "Scale"
  bottom: "645"
  top: "645"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "646"
  type: "ReLU"
  bottom: "645"
  top: "646"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature2"
  type: "Convolution"
  bottom: "646"
  top: "feature2"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}

