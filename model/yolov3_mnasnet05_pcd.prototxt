layer {
  name: "img"
  type: "Input"
  top: "img"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 416
      dim: 416
    }
  }
}
layer {
  name: "441"
  type: "Convolution"
  bottom: "img"
  top: "441"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "442_bn"
  type: "BatchNorm"
  bottom: "441"
  top: "442"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "442"
  type: "Scale"
  bottom: "442"
  top: "442"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "443"
  type: "ReLU"
  bottom: "442"
  top: "443"
}
layer {
  name: "444"
  type: "Convolution"
  bottom: "443"
  top: "444"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "445_bn"
  type: "BatchNorm"
  bottom: "444"
  top: "445"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "445"
  type: "Scale"
  bottom: "445"
  top: "445"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "446"
  type: "ReLU"
  bottom: "445"
  top: "446"
}
layer {
  name: "447"
  type: "Convolution"
  bottom: "446"
  top: "447"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "448_bn"
  type: "BatchNorm"
  bottom: "447"
  top: "448"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "448"
  type: "Scale"
  bottom: "448"
  top: "448"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "449"
  type: "Convolution"
  bottom: "448"
  top: "449"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "450_bn"
  type: "BatchNorm"
  bottom: "449"
  top: "450"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "450"
  type: "Scale"
  bottom: "450"
  top: "450"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "451"
  type: "ReLU"
  bottom: "450"
  top: "451"
}
layer {
  name: "452"
  type: "Convolution"
  bottom: "451"
  top: "452"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "453_bn"
  type: "BatchNorm"
  bottom: "452"
  top: "453"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "453"
  type: "Scale"
  bottom: "453"
  top: "453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "454"
  type: "ReLU"
  bottom: "453"
  top: "454"
}
layer {
  name: "455"
  type: "Convolution"
  bottom: "454"
  top: "455"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "456_bn"
  type: "BatchNorm"
  bottom: "455"
  top: "456"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "456"
  type: "Scale"
  bottom: "456"
  top: "456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "457"
  type: "Convolution"
  bottom: "456"
  top: "457"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "458_bn"
  type: "BatchNorm"
  bottom: "457"
  top: "458"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "458"
  type: "Scale"
  bottom: "458"
  top: "458"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "459"
  type: "ReLU"
  bottom: "458"
  top: "459"
}
layer {
  name: "460"
  type: "Convolution"
  bottom: "459"
  top: "460"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "461_bn"
  type: "BatchNorm"
  bottom: "460"
  top: "461"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "461"
  type: "Scale"
  bottom: "461"
  top: "461"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "462"
  type: "ReLU"
  bottom: "461"
  top: "462"
}
layer {
  name: "463"
  type: "Convolution"
  bottom: "462"
  top: "463"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "464_bn"
  type: "BatchNorm"
  bottom: "463"
  top: "464"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "464"
  type: "Scale"
  bottom: "464"
  top: "464"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "465"
  type: "Eltwise"
  bottom: "464"
  bottom: "456"
  top: "465"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "466"
  type: "Convolution"
  bottom: "465"
  top: "466"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "467_bn"
  type: "BatchNorm"
  bottom: "466"
  top: "467"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "467"
  type: "Scale"
  bottom: "467"
  top: "467"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "468"
  type: "ReLU"
  bottom: "467"
  top: "468"
}
layer {
  name: "469"
  type: "Convolution"
  bottom: "468"
  top: "469"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "470_bn"
  type: "BatchNorm"
  bottom: "469"
  top: "470"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "470"
  type: "Scale"
  bottom: "470"
  top: "470"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "471"
  type: "ReLU"
  bottom: "470"
  top: "471"
}
layer {
  name: "472"
  type: "Convolution"
  bottom: "471"
  top: "472"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "473_bn"
  type: "BatchNorm"
  bottom: "472"
  top: "473"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "473"
  type: "Scale"
  bottom: "473"
  top: "473"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "474"
  type: "Eltwise"
  bottom: "473"
  bottom: "465"
  top: "474"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "475"
  type: "Convolution"
  bottom: "474"
  top: "475"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "476_bn"
  type: "BatchNorm"
  bottom: "475"
  top: "476"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "476"
  type: "Scale"
  bottom: "476"
  top: "476"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "477"
  type: "ReLU"
  bottom: "476"
  top: "477"
}
layer {
  name: "478"
  type: "Convolution"
  bottom: "477"
  top: "478"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "479_bn"
  type: "BatchNorm"
  bottom: "478"
  top: "479"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "479"
  type: "Scale"
  bottom: "479"
  top: "479"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "480"
  type: "ReLU"
  bottom: "479"
  top: "480"
}
layer {
  name: "481"
  type: "Convolution"
  bottom: "480"
  top: "481"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "482_bn"
  type: "BatchNorm"
  bottom: "481"
  top: "482"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "482"
  type: "Scale"
  bottom: "482"
  top: "482"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "483"
  type: "Convolution"
  bottom: "482"
  top: "483"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "484_bn"
  type: "BatchNorm"
  bottom: "483"
  top: "484"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "484"
  type: "Scale"
  bottom: "484"
  top: "484"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "485"
  type: "ReLU"
  bottom: "484"
  top: "485"
}
layer {
  name: "486"
  type: "Convolution"
  bottom: "485"
  top: "486"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 72
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "487_bn"
  type: "BatchNorm"
  bottom: "486"
  top: "487"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "487"
  type: "Scale"
  bottom: "487"
  top: "487"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "488"
  type: "ReLU"
  bottom: "487"
  top: "488"
}
layer {
  name: "489"
  type: "Convolution"
  bottom: "488"
  top: "489"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "490_bn"
  type: "BatchNorm"
  bottom: "489"
  top: "490"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "490"
  type: "Scale"
  bottom: "490"
  top: "490"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "491"
  type: "Eltwise"
  bottom: "490"
  bottom: "482"
  top: "491"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "492"
  type: "Convolution"
  bottom: "491"
  top: "492"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "493_bn"
  type: "BatchNorm"
  bottom: "492"
  top: "493"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "493"
  type: "Scale"
  bottom: "493"
  top: "493"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "494"
  type: "ReLU"
  bottom: "493"
  top: "494"
}
layer {
  name: "495"
  type: "Convolution"
  bottom: "494"
  top: "495"
  convolution_param {
    num_output: 72
    bias_term: false
    group: 72
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "496_bn"
  type: "BatchNorm"
  bottom: "495"
  top: "496"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "496"
  type: "Scale"
  bottom: "496"
  top: "496"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "497"
  type: "ReLU"
  bottom: "496"
  top: "497"
}
layer {
  name: "498"
  type: "Convolution"
  bottom: "497"
  top: "498"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "499_bn"
  type: "BatchNorm"
  bottom: "498"
  top: "499"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "499"
  type: "Scale"
  bottom: "499"
  top: "499"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "500"
  type: "Eltwise"
  bottom: "499"
  bottom: "491"
  top: "500"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "501"
  type: "Convolution"
  bottom: "500"
  top: "501"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "502_bn"
  type: "BatchNorm"
  bottom: "501"
  top: "502"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "502"
  type: "Scale"
  bottom: "502"
  top: "502"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "503"
  type: "ReLU"
  bottom: "502"
  top: "503"
}
layer {
  name: "504"
  type: "Convolution"
  bottom: "503"
  top: "504"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "505_bn"
  type: "BatchNorm"
  bottom: "504"
  top: "505"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "505"
  type: "Scale"
  bottom: "505"
  top: "505"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "506"
  type: "ReLU"
  bottom: "505"
  top: "506"
}
layer {
  name: "507"
  type: "Convolution"
  bottom: "506"
  top: "507"
  convolution_param {
    num_output: 40
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "508_bn"
  type: "BatchNorm"
  bottom: "507"
  top: "508"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "508"
  type: "Scale"
  bottom: "508"
  top: "508"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "509"
  type: "Convolution"
  bottom: "508"
  top: "509"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "510_bn"
  type: "BatchNorm"
  bottom: "509"
  top: "510"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "510"
  type: "Scale"
  bottom: "510"
  top: "510"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "511"
  type: "ReLU"
  bottom: "510"
  top: "511"
}
layer {
  name: "512"
  type: "Convolution"
  bottom: "511"
  top: "512"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 240
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "513_bn"
  type: "BatchNorm"
  bottom: "512"
  top: "513"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "513"
  type: "Scale"
  bottom: "513"
  top: "513"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "514"
  type: "ReLU"
  bottom: "513"
  top: "514"
}
layer {
  name: "515"
  type: "Convolution"
  bottom: "514"
  top: "515"
  convolution_param {
    num_output: 40
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "516_bn"
  type: "BatchNorm"
  bottom: "515"
  top: "516"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "516"
  type: "Scale"
  bottom: "516"
  top: "516"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "517"
  type: "Eltwise"
  bottom: "516"
  bottom: "508"
  top: "517"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "518"
  type: "Convolution"
  bottom: "517"
  top: "518"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "519_bn"
  type: "BatchNorm"
  bottom: "518"
  top: "519"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "519"
  type: "Scale"
  bottom: "519"
  top: "519"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "520"
  type: "ReLU"
  bottom: "519"
  top: "520"
}
layer {
  name: "521"
  type: "Convolution"
  bottom: "520"
  top: "521"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 240
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "522_bn"
  type: "BatchNorm"
  bottom: "521"
  top: "522"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "522"
  type: "Scale"
  bottom: "522"
  top: "522"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "523"
  type: "ReLU"
  bottom: "522"
  top: "523"
}
layer {
  name: "524"
  type: "Convolution"
  bottom: "523"
  top: "524"
  convolution_param {
    num_output: 40
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "525_bn"
  type: "BatchNorm"
  bottom: "524"
  top: "525"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "525"
  type: "Scale"
  bottom: "525"
  top: "525"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "526"
  type: "Eltwise"
  bottom: "525"
  bottom: "517"
  top: "526"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "527"
  type: "Convolution"
  bottom: "526"
  top: "527"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "528_bn"
  type: "BatchNorm"
  bottom: "527"
  top: "528"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "528"
  type: "Scale"
  bottom: "528"
  top: "528"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "529"
  type: "ReLU"
  bottom: "528"
  top: "529"
}
layer {
  name: "530"
  type: "Convolution"
  bottom: "529"
  top: "530"
  convolution_param {
    num_output: 240
    bias_term: false
    group: 240
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "531_bn"
  type: "BatchNorm"
  bottom: "530"
  top: "531"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "531"
  type: "Scale"
  bottom: "531"
  top: "531"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "532"
  type: "ReLU"
  bottom: "531"
  top: "532"
}
layer {
  name: "533"
  type: "Convolution"
  bottom: "532"
  top: "533"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "534_bn"
  type: "BatchNorm"
  bottom: "533"
  top: "534"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "534"
  type: "Scale"
  bottom: "534"
  top: "534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "535"
  type: "Convolution"
  bottom: "534"
  top: "535"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "536_bn"
  type: "BatchNorm"
  bottom: "535"
  top: "536"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "536"
  type: "Scale"
  bottom: "536"
  top: "536"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "537"
  type: "ReLU"
  bottom: "536"
  top: "537"
}
layer {
  name: "538"
  type: "Convolution"
  bottom: "537"
  top: "538"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 288
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "539_bn"
  type: "BatchNorm"
  bottom: "538"
  top: "539"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "539"
  type: "Scale"
  bottom: "539"
  top: "539"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "540"
  type: "ReLU"
  bottom: "539"
  top: "540"
}
layer {
  name: "541"
  type: "Convolution"
  bottom: "540"
  top: "541"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "542_bn"
  type: "BatchNorm"
  bottom: "541"
  top: "542"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "542"
  type: "Scale"
  bottom: "542"
  top: "542"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "543"
  type: "Eltwise"
  bottom: "542"
  bottom: "534"
  top: "543"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "544"
  type: "Convolution"
  bottom: "543"
  top: "544"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "545_bn"
  type: "BatchNorm"
  bottom: "544"
  top: "545"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "545"
  type: "Scale"
  bottom: "545"
  top: "545"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "546"
  type: "ReLU"
  bottom: "545"
  top: "546"
}
layer {
  name: "547"
  type: "Convolution"
  bottom: "546"
  top: "547"
  convolution_param {
    num_output: 288
    bias_term: false
    group: 288
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "548_bn"
  type: "BatchNorm"
  bottom: "547"
  top: "548"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "548"
  type: "Scale"
  bottom: "548"
  top: "548"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "549"
  type: "ReLU"
  bottom: "548"
  top: "549"
}
layer {
  name: "550"
  type: "Convolution"
  bottom: "549"
  top: "550"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "551_bn"
  type: "BatchNorm"
  bottom: "550"
  top: "551"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "551"
  type: "Scale"
  bottom: "551"
  top: "551"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "552"
  type: "Convolution"
  bottom: "551"
  top: "552"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "553_bn"
  type: "BatchNorm"
  bottom: "552"
  top: "553"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "553"
  type: "Scale"
  bottom: "553"
  top: "553"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "554"
  type: "ReLU"
  bottom: "553"
  top: "554"
}
layer {
  name: "555"
  type: "Convolution"
  bottom: "554"
  top: "555"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "556_bn"
  type: "BatchNorm"
  bottom: "555"
  top: "556"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "556"
  type: "Scale"
  bottom: "556"
  top: "556"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "557"
  type: "ReLU"
  bottom: "556"
  top: "557"
}
layer {
  name: "558"
  type: "Convolution"
  bottom: "557"
  top: "558"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "559_bn"
  type: "BatchNorm"
  bottom: "558"
  top: "559"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "559"
  type: "Scale"
  bottom: "559"
  top: "559"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "560"
  type: "Eltwise"
  bottom: "559"
  bottom: "551"
  top: "560"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "561"
  type: "Convolution"
  bottom: "560"
  top: "561"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "562_bn"
  type: "BatchNorm"
  bottom: "561"
  top: "562"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "562"
  type: "Scale"
  bottom: "562"
  top: "562"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "563"
  type: "ReLU"
  bottom: "562"
  top: "563"
}
layer {
  name: "564"
  type: "Convolution"
  bottom: "563"
  top: "564"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "565_bn"
  type: "BatchNorm"
  bottom: "564"
  top: "565"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "565"
  type: "Scale"
  bottom: "565"
  top: "565"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "566"
  type: "ReLU"
  bottom: "565"
  top: "566"
}
layer {
  name: "567"
  type: "Convolution"
  bottom: "566"
  top: "567"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "568_bn"
  type: "BatchNorm"
  bottom: "567"
  top: "568"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "568"
  type: "Scale"
  bottom: "568"
  top: "568"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "569"
  type: "Eltwise"
  bottom: "568"
  bottom: "560"
  top: "569"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "570"
  type: "Convolution"
  bottom: "569"
  top: "570"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "571_bn"
  type: "BatchNorm"
  bottom: "570"
  top: "571"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "571"
  type: "Scale"
  bottom: "571"
  top: "571"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "572"
  type: "ReLU"
  bottom: "571"
  top: "572"
}
layer {
  name: "573"
  type: "Convolution"
  bottom: "572"
  top: "573"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 2
    pad_w: 2
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "574_bn"
  type: "BatchNorm"
  bottom: "573"
  top: "574"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "574"
  type: "Scale"
  bottom: "574"
  top: "574"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "575"
  type: "ReLU"
  bottom: "574"
  top: "575"
}
layer {
  name: "576"
  type: "Convolution"
  bottom: "575"
  top: "576"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "577_bn"
  type: "BatchNorm"
  bottom: "576"
  top: "577"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "577"
  type: "Scale"
  bottom: "577"
  top: "577"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "578"
  type: "Eltwise"
  bottom: "577"
  bottom: "569"
  top: "578"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "579"
  type: "Convolution"
  bottom: "578"
  top: "579"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "580_bn"
  type: "BatchNorm"
  bottom: "579"
  top: "580"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "580"
  type: "Scale"
  bottom: "580"
  top: "580"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "581"
  type: "ReLU"
  bottom: "580"
  top: "581"
}
layer {
  name: "582"
  type: "Convolution"
  bottom: "581"
  top: "582"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "583_bn"
  type: "BatchNorm"
  bottom: "582"
  top: "583"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "583"
  type: "Scale"
  bottom: "583"
  top: "583"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "584"
  type: "ReLU"
  bottom: "583"
  top: "584"
}
layer {
  name: "585"
  type: "Convolution"
  bottom: "584"
  top: "585"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "586_bn"
  type: "BatchNorm"
  bottom: "585"
  top: "586"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "586"
  type: "Scale"
  bottom: "586"
  top: "586"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "587"
  type: "Convolution"
  bottom: "586"
  top: "587"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "588_bn"
  type: "BatchNorm"
  bottom: "587"
  top: "588"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "588"
  type: "Scale"
  bottom: "588"
  top: "588"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "589"
  type: "ReLU"
  bottom: "588"
  top: "589"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "590"
  type: "Convolution"
  bottom: "589"
  top: "590"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "591_bn"
  type: "BatchNorm"
  bottom: "590"
  top: "591"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "591"
  type: "Scale"
  bottom: "591"
  top: "591"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "592"
  type: "ReLU"
  bottom: "591"
  top: "592"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "593"
  type: "Convolution"
  bottom: "592"
  top: "593"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "594_bn"
  type: "BatchNorm"
  bottom: "593"
  top: "594"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "594"
  type: "Scale"
  bottom: "594"
  top: "594"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "595"
  type: "ReLU"
  bottom: "594"
  top: "595"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "596"
  type: "Convolution"
  bottom: "595"
  top: "596"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "597_bn"
  type: "BatchNorm"
  bottom: "596"
  top: "597"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "597"
  type: "Scale"
  bottom: "597"
  top: "597"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "598"
  type: "ReLU"
  bottom: "597"
  top: "598"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "599"
  type: "Convolution"
  bottom: "598"
  top: "599"
  convolution_param {
    num_output: 80
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "600_bn"
  type: "BatchNorm"
  bottom: "599"
  top: "600"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "600"
  type: "Scale"
  bottom: "600"
  top: "600"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "601"
  type: "ReLU"
  bottom: "600"
  top: "601"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "602"
  type: "Convolution"
  bottom: "601"
  top: "602"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "603_bn"
  type: "BatchNorm"
  bottom: "602"
  top: "603"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "603"
  type: "Scale"
  bottom: "603"
  top: "603"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "604"
  type: "ReLU"
  bottom: "603"
  top: "604"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature0"
  type: "Convolution"
  bottom: "604"
  top: "feature0"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "606"
  type: "Convolution"
  bottom: "601"
  top: "606"
  convolution_param {
    num_output: 40
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "607_bn"
  type: "BatchNorm"
  bottom: "606"
  top: "607"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "607"
  type: "Scale"
  bottom: "607"
  top: "607"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "608"
  type: "ReLU"
  bottom: "607"
  top: "608"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "610"
  type: "Deconvolution"
  bottom: "608"
  top: "610"
  convolution_param {
    num_output: 40
    bias_term: false
    kernel_size: 2
    group: 40
    stride: 2
  }
}
layer {
  name: "611"
  type: "Concat"
  bottom: "610"
  bottom: "543"
  top: "611"
  concat_param {
    axis: 1
  }
}
layer {
  name: "612"
  type: "Convolution"
  bottom: "611"
  top: "612"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "613_bn"
  type: "BatchNorm"
  bottom: "612"
  top: "613"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "613"
  type: "Scale"
  bottom: "613"
  top: "613"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "614"
  type: "ReLU"
  bottom: "613"
  top: "614"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "615"
  type: "Convolution"
  bottom: "614"
  top: "615"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "616_bn"
  type: "BatchNorm"
  bottom: "615"
  top: "616"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "616"
  type: "Scale"
  bottom: "616"
  top: "616"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "617"
  type: "ReLU"
  bottom: "616"
  top: "617"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "618"
  type: "Convolution"
  bottom: "617"
  top: "618"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "619_bn"
  type: "BatchNorm"
  bottom: "618"
  top: "619"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "619"
  type: "Scale"
  bottom: "619"
  top: "619"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "620"
  type: "ReLU"
  bottom: "619"
  top: "620"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "621"
  type: "Convolution"
  bottom: "620"
  top: "621"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "622_bn"
  type: "BatchNorm"
  bottom: "621"
  top: "622"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "622"
  type: "Scale"
  bottom: "622"
  top: "622"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "623"
  type: "ReLU"
  bottom: "622"
  top: "623"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "624"
  type: "Convolution"
  bottom: "623"
  top: "624"
  convolution_param {
    num_output: 29
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "625_bn"
  type: "BatchNorm"
  bottom: "624"
  top: "625"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "625"
  type: "Scale"
  bottom: "625"
  top: "625"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "626"
  type: "ReLU"
  bottom: "625"
  top: "626"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "627"
  type: "Convolution"
  bottom: "626"
  top: "627"
  convolution_param {
    num_output: 58
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "628_bn"
  type: "BatchNorm"
  bottom: "627"
  top: "628"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "628"
  type: "Scale"
  bottom: "628"
  top: "628"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "629"
  type: "ReLU"
  bottom: "628"
  top: "629"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature1"
  type: "Convolution"
  bottom: "629"
  top: "feature1"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "631"
  type: "Convolution"
  bottom: "626"
  top: "631"
  convolution_param {
    num_output: 14
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "632_bn"
  type: "BatchNorm"
  bottom: "631"
  top: "632"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "632"
  type: "Scale"
  bottom: "632"
  top: "632"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "633"
  type: "ReLU"
  bottom: "632"
  top: "633"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "635"
  type: "Deconvolution"
  bottom: "633"
  top: "635"
  convolution_param {
    num_output: 14
    bias_term: false
    kernel_size: 2
    group: 14
    stride: 2
  }
}
layer {
  name: "636"
  type: "Concat"
  bottom: "635"
  bottom: "500"
  top: "636"
  concat_param {
    axis: 1
  }
}
layer {
  name: "637"
  type: "Convolution"
  bottom: "636"
  top: "637"
  convolution_param {
    num_output: 12
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "638_bn"
  type: "BatchNorm"
  bottom: "637"
  top: "638"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "638"
  type: "Scale"
  bottom: "638"
  top: "638"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "639"
  type: "ReLU"
  bottom: "638"
  top: "639"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "640"
  type: "Convolution"
  bottom: "639"
  top: "640"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "641_bn"
  type: "BatchNorm"
  bottom: "640"
  top: "641"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "641"
  type: "Scale"
  bottom: "641"
  top: "641"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "642"
  type: "ReLU"
  bottom: "641"
  top: "642"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "643"
  type: "Convolution"
  bottom: "642"
  top: "643"
  convolution_param {
    num_output: 12
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "644_bn"
  type: "BatchNorm"
  bottom: "643"
  top: "644"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "644"
  type: "Scale"
  bottom: "644"
  top: "644"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "645"
  type: "ReLU"
  bottom: "644"
  top: "645"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "646"
  type: "Convolution"
  bottom: "645"
  top: "646"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "647_bn"
  type: "BatchNorm"
  bottom: "646"
  top: "647"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "647"
  type: "Scale"
  bottom: "647"
  top: "647"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "648"
  type: "ReLU"
  bottom: "647"
  top: "648"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "649"
  type: "Convolution"
  bottom: "648"
  top: "649"
  convolution_param {
    num_output: 12
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "650_bn"
  type: "BatchNorm"
  bottom: "649"
  top: "650"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "650"
  type: "Scale"
  bottom: "650"
  top: "650"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "651"
  type: "ReLU"
  bottom: "650"
  top: "651"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "652"
  type: "Convolution"
  bottom: "651"
  top: "652"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "653_bn"
  type: "BatchNorm"
  bottom: "652"
  top: "653"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "653"
  type: "Scale"
  bottom: "653"
  top: "653"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "654"
  type: "ReLU"
  bottom: "653"
  top: "654"
  relu_param {
    negative_slope: 0.10000000149011612
  }
}
layer {
  name: "feature2"
  type: "Convolution"
  bottom: "654"
  top: "feature2"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}

